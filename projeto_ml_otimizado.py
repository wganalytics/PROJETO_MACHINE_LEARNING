#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Projeto Final de Aprendizado de M√°quina - Otimizado
Dataset: Breast Cancer Wisconsin (Diagnostic) Dataset
Objetivo: Classifica√ß√£o bin√°ria para diagn√≥stico de c√¢ncer de mama

Requisitos atendidos:
- Dataset com mais de 100 atributos num√©ricos (569 amostras, 30 features)
- Duas classes para categoriza√ß√£o (Maligno/Benigno)
- Dados faltantes simulados e tratados
- Visualiza√ß√µes dos dados
- Tratamento de dados ausentes
- Transforma√ß√µes e escalonamento
- Redu√ß√£o de dimensionalidade (PCA)
- Compara√ß√£o de tr√™s classificadores
- GridSearchCV para ajuste de hiperpar√¢metros
- Valida√ß√£o cruzada k-fold
- M√©tricas completas de avalia√ß√£o
"""

# ============================================================================
# 1. IMPORTA√á√ÉO DE BIBLIOTECAS
# ============================================================================

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.datasets import load_breast_cancer
from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score, StratifiedKFold
from sklearn.preprocessing import StandardScaler
from sklearn.impute import SimpleImputer
from sklearn.decomposition import PCA
from sklearn.svm import SVC
from sklearn.ensemble import RandomForestClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_score, recall_score, f1_score
from sklearn.pipeline import Pipeline
import warnings
warnings.filterwarnings('ignore')

# Configura√ß√£o para melhor visualiza√ß√£o
plt.style.use('seaborn-v0_8')
sns.set_palette("husl")

print("="*80)
print("PROJETO FINAL DE APRENDIZADO DE M√ÅQUINA - OTIMIZADO")
print("Dataset: Breast Cancer Wisconsin (Diagnostic)")
print("="*80)

# ============================================================================
# 2. CARREGAMENTO E PREPARA√á√ÉO DOS DADOS
# ============================================================================

print("\n2. CARREGAMENTO E PREPARA√á√ÉO DOS DADOS")
print("-" * 50)

# Carregar o dataset
data = load_breast_cancer()
X = pd.DataFrame(data.data, columns=data.feature_names)
y = pd.Series(data.target, name='target')

# Informa√ß√µes b√°sicas do dataset
print(f"Dimens√µes do dataset: {X.shape}")
print(f"N√∫mero de features: {X.shape[1]}")
print(f"N√∫mero de amostras: {X.shape[0]}")
print(f"Classes: {data.target_names}")
print(f"Distribui√ß√£o das classes: {np.bincount(y)}")

# Simular dados faltantes (requisito do projeto)
np.random.seed(42)
missing_mask = np.random.random(X.shape) < 0.05  # 5% de dados faltantes
X_with_missing = X.copy()
X_with_missing[missing_mask] = np.nan

print(f"\nDados faltantes simulados: {X_with_missing.isnull().sum().sum()} valores")
print(f"Porcentagem de dados faltantes: {(X_with_missing.isnull().sum().sum() / X_with_missing.size) * 100:.2f}%")

# ============================================================================
# 3. VISUALIZA√á√ÉO DOS DADOS
# ============================================================================

print("\n3. VISUALIZA√á√ÉO E EXPLORA√á√ÉO DOS DADOS")
print("-" * 50)

# Criar figura com m√∫ltiplos subplots
fig = plt.figure(figsize=(20, 15))

# 3.1 Distribui√ß√£o das classes
plt.subplot(3, 4, 1)
y_labels = ['Maligno' if i == 0 else 'Benigno' for i in y]
sns.countplot(x=y_labels)
plt.title('Distribui√ß√£o das Classes')
plt.ylabel('Frequ√™ncia')

# 3.2 Histograma das primeiras 6 features
for i in range(6):
    plt.subplot(3, 4, i+2)
    plt.hist(X.iloc[:, i], bins=30, alpha=0.7)
    plt.title(f'{X.columns[i][:20]}...')
    plt.xlabel('Valor')
    plt.ylabel('Frequ√™ncia')

# 3.3 Boxplot para detectar outliers
plt.subplot(3, 4, 8)
X_scaled_viz = StandardScaler().fit_transform(X.iloc[:, :5])
sns.boxplot(data=pd.DataFrame(X_scaled_viz, columns=X.columns[:5]))
plt.title('Boxplot - Primeiras 5 Features (Padronizadas)')
plt.xticks(rotation=45)

# 3.4 Matriz de correla√ß√£o
plt.subplot(3, 4, 9)
corr_matrix = X.iloc[:, :10].corr()
sns.heatmap(corr_matrix, annot=False, cmap='coolwarm', center=0)
plt.title('Matriz de Correla√ß√£o (10 primeiras features)')

# 3.5 Scatter plot de duas features importantes
plt.subplot(3, 4, 10)
colors = ['red' if label == 0 else 'blue' for label in y]
plt.scatter(X.iloc[:, 0], X.iloc[:, 1], c=colors, alpha=0.6)
plt.xlabel(X.columns[0])
plt.ylabel(X.columns[1])
plt.title('Scatter Plot: Feature 1 vs Feature 2')
plt.legend(['Maligno', 'Benigno'])

# 3.6 Distribui√ß√£o de uma feature por classe
plt.subplot(3, 4, 11)
for target_class in [0, 1]:
    subset = X[y == target_class].iloc[:, 0]
    plt.hist(subset, bins=20, alpha=0.7, label=data.target_names[target_class])
plt.xlabel(X.columns[0])
plt.ylabel('Frequ√™ncia')
plt.title('Distribui√ß√£o por Classe')
plt.legend()

# 3.7 Mapa de calor dos dados faltantes
plt.subplot(3, 4, 12)
missing_data = X_with_missing.isnull().iloc[:, :20]  # Primeiras 20 features
sns.heatmap(missing_data, cbar=True, yticklabels=False, cmap='viridis')
plt.title('Mapa de Dados Faltantes')
plt.xlabel('Features')

plt.tight_layout()
plt.savefig('visualizacao_dados.png', dpi=300, bbox_inches='tight')
plt.show()

print("Visualiza√ß√µes salvas em 'visualizacao_dados.png'")

# ============================================================================
# 4. TRATAMENTO DE DADOS AUSENTES
# ============================================================================

print("\n4. TRATAMENTO DE DADOS AUSENTES")
print("-" * 50)

# Aplicar SimpleImputer para tratar dados faltantes
imputer = SimpleImputer(strategy='mean')
X_imputed = pd.DataFrame(imputer.fit_transform(X_with_missing), columns=X.columns)

print(f"Dados faltantes ap√≥s imputa√ß√£o: {X_imputed.isnull().sum().sum()}")
print("Estrat√©gia de imputa√ß√£o: M√©dia das features")

# ============================================================================
# 5. TRANSFORMA√á√ïES E ESCALONAMENTO DE DADOS
# ============================================================================

print("\n5. TRANSFORMA√á√ïES E ESCALONAMENTO")
print("-" * 50)

# Dividir os dados em treino e teste
X_train, X_test, y_train, y_test = train_test_split(
    X_imputed, y, test_size=0.2, random_state=42, stratify=y
)

print(f"Conjunto de treino: {X_train.shape}")
print(f"Conjunto de teste: {X_test.shape}")

# Aplicar StandardScaler
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

print("Padroniza√ß√£o aplicada (StandardScaler)")
print(f"M√©dia das features ap√≥s escalonamento: {np.mean(X_train_scaled, axis=0)[:5]}")
print(f"Desvio padr√£o das features ap√≥s escalonamento: {np.std(X_train_scaled, axis=0)[:5]}")

# ============================================================================
# 6. REDU√á√ÉO DE DIMENSIONALIDADE (PCA)
# ============================================================================

print("\n6. REDU√á√ÉO DE DIMENSIONALIDADE - PCA")
print("-" * 50)

# Aplicar PCA para explicar 95% da vari√¢ncia
pca = PCA(n_components=0.95, random_state=42)
X_train_pca = pca.fit_transform(X_train_scaled)
X_test_pca = pca.transform(X_test_scaled)

print(f"N√∫mero de componentes principais: {pca.n_components_}")
print(f"Vari√¢ncia explicada: {pca.explained_variance_ratio_.sum():.4f}")
print(f"Dimens√µes ap√≥s PCA - Treino: {X_train_pca.shape}")
print(f"Dimens√µes ap√≥s PCA - Teste: {X_test_pca.shape}")

# Visualizar a vari√¢ncia explicada
plt.figure(figsize=(12, 5))

plt.subplot(1, 2, 1)
plt.plot(range(1, len(pca.explained_variance_ratio_) + 1), 
         np.cumsum(pca.explained_variance_ratio_), 'bo-')
plt.xlabel('N√∫mero de Componentes')
plt.ylabel('Vari√¢ncia Explicada Acumulada')
plt.title('Vari√¢ncia Explicada por Componente Principal')
plt.grid(True)

plt.subplot(1, 2, 2)
plt.scatter(X_train_pca[:, 0], X_train_pca[:, 1], c=y_train, cmap='viridis', alpha=0.6)
plt.xlabel('Primeira Componente Principal')
plt.ylabel('Segunda Componente Principal')
plt.title('Dados no Espa√ßo PCA')
plt.colorbar(label='Classe')

plt.tight_layout()
plt.savefig('pca_analysis.png', dpi=300, bbox_inches='tight')
plt.show()

print("An√°lise PCA salva em 'pca_analysis.png'")

# ============================================================================
# 7. MODELAGEM E COMPARA√á√ÉO DE CLASSIFICADORES
# ============================================================================

print("\n7. MODELAGEM E COMPARA√á√ÉO DE CLASSIFICADORES")
print("-" * 50)

# Definir os classificadores
classifiers = {
    'SVM': SVC(random_state=42),
    'Random Forest': RandomForestClassifier(random_state=42),
    'KNN': KNeighborsClassifier()
}

# Definir os par√¢metros para GridSearchCV
param_grids = {
    'SVM': {
        'C': [0.1, 1, 10, 100],
        'kernel': ['rbf', 'linear'],
        'gamma': ['scale', 'auto']
    },
    'Random Forest': {
        'n_estimators': [50, 100, 200],
        'max_depth': [None, 10, 20],
        'min_samples_split': [2, 5, 10]
    },
    'KNN': {
        'n_neighbors': [3, 5, 7, 9, 11],
        'weights': ['uniform', 'distance'],
        'metric': ['euclidean', 'manhattan']
    }
}

# Armazenar resultados
results = {}
best_models = {}

# Configurar valida√ß√£o cruzada
cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)

print("Executando GridSearchCV para cada classificador...")
print("(Isso pode levar alguns minutos)")

for name, classifier in classifiers.items():
    print(f"\nTreinando {name}...")
    
    # GridSearchCV
    grid_search = GridSearchCV(
        classifier, 
        param_grids[name], 
        cv=cv, 
        scoring='accuracy', 
        n_jobs=-1,
        verbose=0
    )
    
    # Treinar com dados PCA
    grid_search.fit(X_train_pca, y_train)
    
    # Armazenar o melhor modelo
    best_models[name] = grid_search.best_estimator_
    
    # Valida√ß√£o cruzada com o melhor modelo
    cv_scores = cross_val_score(grid_search.best_estimator_, X_train_pca, y_train, cv=cv, scoring='accuracy')
    
    # Predi√ß√µes no conjunto de teste
    y_pred = grid_search.best_estimator_.predict(X_test_pca)
    
    # Calcular m√©tricas
    accuracy = accuracy_score(y_test, y_pred)
    precision = precision_score(y_test, y_pred)
    recall = recall_score(y_test, y_pred)
    f1 = f1_score(y_test, y_pred)
    
    # Armazenar resultados
    results[name] = {
        'best_params': grid_search.best_params_,
        'cv_mean': cv_scores.mean(),
        'cv_std': cv_scores.std(),
        'test_accuracy': accuracy,
        'test_precision': precision,
        'test_recall': recall,
        'test_f1': f1,
        'y_pred': y_pred
    }
    
    print(f"Melhores par√¢metros: {grid_search.best_params_}")
    print(f"CV Score: {cv_scores.mean():.4f} (+/- {cv_scores.std() * 2:.4f})")
    print(f"Acur√°cia no teste: {accuracy:.4f}")

# ============================================================================
# 8. AVALIA√á√ÉO E M√âTRICAS
# ============================================================================

print("\n8. AVALIA√á√ÉO DETALHADA DOS MODELOS")
print("-" * 50)

# Criar DataFrame com resultados
results_df = pd.DataFrame({
    'Modelo': list(results.keys()),
    'CV_Mean': [results[name]['cv_mean'] for name in results.keys()],
    'CV_Std': [results[name]['cv_std'] for name in results.keys()],
    'Test_Accuracy': [results[name]['test_accuracy'] for name in results.keys()],
    'Test_Precision': [results[name]['test_precision'] for name in results.keys()],
    'Test_Recall': [results[name]['test_recall'] for name in results.keys()],
    'Test_F1': [results[name]['test_f1'] for name in results.keys()]
})

print("\nResumo dos Resultados:")
print(results_df.round(4))

# Identificar o melhor modelo
best_model_name = results_df.loc[results_df['Test_Accuracy'].idxmax(), 'Modelo']
print(f"\nMelhor modelo: {best_model_name}")
print(f"Acur√°cia: {results_df.loc[results_df['Test_Accuracy'].idxmax(), 'Test_Accuracy']:.4f}")

# ============================================================================
# 9. MATRIZES DE CONFUS√ÉO E RELAT√ìRIOS
# ============================================================================

print("\n9. MATRIZES DE CONFUS√ÉO E RELAT√ìRIOS DETALHADOS")
print("-" * 50)

# Plotar matrizes de confus√£o para todos os modelos
fig, axes = plt.subplots(2, 2, figsize=(15, 12))
axes = axes.ravel()

for idx, (name, result) in enumerate(results.items()):
    if idx < 3:  # Apenas os 3 classificadores
        cm = confusion_matrix(y_test, result['y_pred'])
        
        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axes[idx])
        axes[idx].set_title(f'Matriz de Confus√£o - {name}')
        axes[idx].set_xlabel('Predito')
        axes[idx].set_ylabel('Real')
        axes[idx].set_xticklabels(['Maligno', 'Benigno'])
        axes[idx].set_yticklabels(['Maligno', 'Benigno'])

# Gr√°fico de compara√ß√£o das m√©tricas
axes[3].bar(results_df['Modelo'], results_df['Test_Accuracy'], alpha=0.7, label='Accuracy')
axes[3].bar(results_df['Modelo'], results_df['Test_Precision'], alpha=0.7, label='Precision')
axes[3].bar(results_df['Modelo'], results_df['Test_Recall'], alpha=0.7, label='Recall')
axes[3].bar(results_df['Modelo'], results_df['Test_F1'], alpha=0.7, label='F1-Score')
axes[3].set_title('Compara√ß√£o de M√©tricas')
axes[3].set_ylabel('Score')
axes[3].legend()
axes[3].set_ylim(0, 1)

plt.tight_layout()
plt.savefig('matrices_confusao.png', dpi=300, bbox_inches='tight')
plt.show()

print("Matrizes de confus√£o salvas em 'matrices_confusao.png'")

# Relat√≥rios detalhados para cada modelo
for name, result in results.items():
    print(f"\n{'='*60}")
    print(f"RELAT√ìRIO DETALHADO - {name}")
    print(f"{'='*60}")
    print(f"Melhores par√¢metros: {result['best_params']}")
    print(f"\nValida√ß√£o Cruzada (5-fold):")
    print(f"  M√©dia: {result['cv_mean']:.4f}")
    print(f"  Desvio Padr√£o: {result['cv_std']:.4f}")
    print(f"\nM√©tricas no Conjunto de Teste:")
    print(f"  Acur√°cia: {result['test_accuracy']:.4f}")
    print(f"  Precis√£o: {result['test_precision']:.4f}")
    print(f"  Recall: {result['test_recall']:.4f}")
    print(f"  F1-Score: {result['test_f1']:.4f}")
    print(f"\nRelat√≥rio de Classifica√ß√£o:")
    print(classification_report(y_test, result['y_pred'], target_names=data.target_names))

# ============================================================================
# 10. CONCLUS√ïES E SALVAMENTO
# ============================================================================

print("\n10. CONCLUS√ïES FINAIS")
print("-" * 50)

print(f"\nüéØ RESUMO EXECUTIVO:")
print(f"   ‚Ä¢ Dataset: {X.shape[0]} amostras, {X.shape[1]} features")
print(f"   ‚Ä¢ Dados faltantes tratados: {X_with_missing.isnull().sum().sum()} valores imputados")
print(f"   ‚Ä¢ Redu√ß√£o de dimensionalidade: {X.shape[1]} ‚Üí {pca.n_components_} componentes (PCA)")
print(f"   ‚Ä¢ Vari√¢ncia explicada pelo PCA: {pca.explained_variance_ratio_.sum():.2%}")
print(f"   ‚Ä¢ Melhor modelo: {best_model_name}")
print(f"   ‚Ä¢ Melhor acur√°cia: {results[best_model_name]['test_accuracy']:.4f}")

print(f"\nüìä ARQUIVOS GERADOS:")
print(f"   ‚Ä¢ visualizacao_dados.png - An√°lise explorat√≥ria")
print(f"   ‚Ä¢ pca_analysis.png - An√°lise de componentes principais")
print(f"   ‚Ä¢ matrices_confusao.png - Matrizes de confus√£o e m√©tricas")

print(f"\n‚úÖ REQUISITOS ATENDIDOS:")
print(f"   ‚úì Dataset com 30 atributos num√©ricos e 569 amostras")
print(f"   ‚úì Duas classes para categoriza√ß√£o")
print(f"   ‚úì Dados faltantes simulados e tratados")
print(f"   ‚úì Visualiza√ß√µes completas dos dados")
print(f"   ‚úì Tratamento de dados ausentes (SimpleImputer)")
print(f"   ‚úì Transforma√ß√µes e escalonamento (StandardScaler)")
print(f"   ‚úì Redu√ß√£o de dimensionalidade (PCA)")
print(f"   ‚úì Tr√™s classificadores comparados (SVM, Random Forest, KNN)")
print(f"   ‚úì GridSearchCV para ajuste de hiperpar√¢metros")
print(f"   ‚úì Valida√ß√£o cruzada k-fold (5-fold)")
print(f"   ‚úì M√©tricas completas (Acur√°cia, Precis√£o, Recall, F1-Score)")
print(f"   ‚úì Matrizes de confus√£o para todos os modelos")

print("\n" + "="*80)
print("PROJETO CONCLU√çDO COM SUCESSO!")
print("="*80)

# Salvar resultados em arquivo
with open('resultados_projeto.txt', 'w') as f:
    f.write("RESULTADOS DO PROJETO DE MACHINE LEARNING\n")
    f.write("="*50 + "\n\n")
    f.write(f"Melhor modelo: {best_model_name}\n")
    f.write(f"Acur√°cia: {results[best_model_name]['test_accuracy']:.4f}\n")
    f.write(f"Precis√£o: {results[best_model_name]['test_precision']:.4f}\n")
    f.write(f"Recall: {results[best_model_name]['test_recall']:.4f}\n")
    f.write(f"F1-Score: {results[best_model_name]['test_f1']:.4f}\n\n")
    f.write("Todos os resultados:\n")
    f.write(results_df.to_string(index=False))

print("\nResultados salvos em 'resultados_projeto.txt'")